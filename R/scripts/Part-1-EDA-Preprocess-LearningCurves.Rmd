---
title: "Titanic: Machine Learning from Disaster, Part I - Preprocessing"
author: "Sanjeev Gadre"
date: "July 15, 2019"
output:
    md_document:
        toc: TRUE
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r libraries, echo=FALSE, message=FALSE}
library(knitr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(ROCR)

```

```{r functions}
na.count = function (dat){
  dat %>% apply(., 2, is.na) %>% apply(.,2,sum) %>% .[.!=0]
}

```

### Getting the Data

1.  We start by getting a sense of the training data and its structure.
2.  We add a column "Survived" to the test data and assign a default value of "0".
3.  Finally, we combide train and test data, for easier changes to the dataframe structure, imputing missing values and analysis

```{r get-data}

train = read.csv("../data/train.csv")

head(train)
str(train)

test = read.csv("../data/test.csv")
test$Survived = 0

dat = rbind(train, test)
indx = 1:nrow(train)

```

### Data Pre-processing

We run the following data pre-processing steps:
1. Convert the feature type for `Survived`, `Pclass` from `<int>` to `<fctr>`.
2. Convert the feature type for `Name`, `Cabin` from `<fctr>` to `<char>`.
3. Convert the feature type for `Ticket` from `<fct>` to `<int>`.

Finally, we get separate the train and test data subsets.

```{r pre-proc-1}

dat$Survived = factor(dat$Survived)
dat$Pclass = factor(dat$Pclass)
dat$Name = as.character(dat$Name)
dat$Cabin = as.character(dat$Cabin)
dat$Ticket = as.integer(dat$Ticket)
str(dat)

train = dat[indx,]
test = dat[-indx,]
rm(dat)

```

### Exploratory Data Analysis

From the list of features available, it is reasonable to guess that the survival of a passenger would likely **not** depend on `Name`, `Ticket` and `Cabin`. 

For the remaining features we get a distribution of their respective values for the train and test subset to ascertain any significant differences between the two.

```{r eda-1}
plot.age = ggplot()+ 
    geom_density(data = train, aes(x=Age, fill = "Train"), size = 1, na.rm = TRUE, alpha = 0.5)+ 
    geom_density(data = test, aes(x=Age, fill = "Test"), size = 1, na.rm = TRUE, alpha = 0.5)+
    scale_fill_manual(name = "Subsets", values = c(Train = "red", Test = "blue"))+ ylab("")
plot.sibsp = ggplot()+ 
    geom_density(data = train, aes(x=SibSp, fill = "Train"), size = 1, na.rm = TRUE, alpha = 0.5)+ 
    geom_density(data = test, aes(x=SibSp, fill = "Test"), size = 1, na.rm = TRUE, alpha = 0.5)+
    scale_fill_manual(name = "Subsets", values = c(Train = "red", Test = "blue"))+ ylab("")
plot.parch = ggplot()+ 
    geom_density(data = train, aes(x=Parch, fill = "Train"), size = 1, na.rm = TRUE, alpha = 0.5)+ 
    geom_density(data = test, aes(x=Parch, fill = "Test"), size = 1, na.rm = TRUE, alpha = 0.5)+
    scale_fill_manual(name = "Subsets", values = c(Train = "red", Test = "blue"))+ ylab("")
plot.fare = ggplot()+ 
    geom_density(data = train, aes(x=Fare, fill = "Train"), size = 1, na.rm = TRUE, alpha = 0.5)+ 
    geom_density(data = test, aes(x=Fare, fill = "Test"), size = 1, na.rm = TRUE, alpha = 0.5)+
    scale_fill_manual(name = "Subsets", values = c(Train = "red", Test = "blue"))+ ylab("")
grid.arrange(plot.age, plot.sibsp, plot.parch, plot.fare, ncol = 2)

train.subset = table(train$Pclass) %>% prop.table() %>% round(4) %>% as.vector()
test.subset = table(test$Pclass) %>% prop.table() %>% round(4) %>% as.vector()
table.pclass = rbind(train.subset, test.subset); colnames(table.pclass) = levels(train$Pclass)
writeLines("\nProportion of passengers stratified by Passenger Class")
table.pclass

train.subset = table(train$Sex) %>% prop.table() %>% round(4) %>% as.vector()
test.subset = table(test$Sex) %>% prop.table() %>% round(4) %>% as.vector()
table.sex = rbind(train.subset, test.subset); colnames(table.sex) = levels(train$Sex)
writeLines("\nProportion of passengers stratified by Passenger Sex")
table.sex


train.subset = table(train$Embarked) %>% prop.table() %>% round(4) %>% as.vector()
test.subset = table(test$Embarked) %>% prop.table() %>% round(4) %>% as.vector()
table.embarked = rbind(train.subset, test.subset); colnames(table.embarked) = levels(train$Embarked) 
writeLines("\nProportion of passengers stratified by Passenger Embarkation Port")
table.embarked

```

There doesn't seem to be any meaningful difference in the distribution of features between the train and test subset, except for `Embarked` where the test subset has less of proportion of passengers boarding from **S**.
    There seem to be some passengers in train subset that are reporting `<blank>` under `Embarked` but there are none like these in the test subset

We now get for the train subset features, distribution of their respective values for the Survivors and non-Survivors

```{r eda-2}
plot.age = train %>% ggplot(aes(Age, color = Survived))+ geom_density(size = 1, na.rm = TRUE)+ ylab("")
plot.sibsp = train %>% ggplot(aes(SibSp, color = Survived))+ geom_density(size = 1, na.rm = TRUE)+ ylab("")
plot.parch = train %>% ggplot(aes(Parch, color = Survived))+ geom_density(size = 1, na.rm = TRUE)+ ylab("")
plot.fare = train %>% ggplot(aes(Fare, color = Survived))+ geom_density(size = 1, na.rm = TRUE)+ ylab("")
grid.arrange(plot.age, plot.sibsp, plot.parch, plot.fare)

writeLines("\nSurvival Rate as a function of factor variables\n")
table(Survived = train$Survived, Pclass = train$Pclass) %>% prop.table(2) %>% round(digits = 4)
table(Survived = train$Survived, Sex = train$Sex) %>% prop.table(2) %>% round(digits = 4)
table(Survived = train$Survived, Embarked = train$Embarked) %>% prop.table(2) %>% round(digits = 4)

writeLines("\n")
writeLines("The table below enumerates the features from the train dataset that report NA values and the count of NA values under respective features\n")
na.count(train)

```

We note that:
1.  There doesn't seem to be a correlation between `Survived` and `Age`, or `SibSp`, or `Parch` or `Fare`.
2.  There is a definite correlation between `Survived` and `Pclass`, and `Sex`, and `Embarked`.
3.  There are some examples in train dataset that have a `<blank>` under the `Embarked` feature and may need imputation.
4.  Finally, the `Age` feature reports 177 `NA`

We get some insight into `Age` by looking at its distribution along `Pclass` and `Sex`.
We also identify the passenger that are reporting `<blank>` under `Embarked`.
    
```{r eda-3}
train %>% ggplot(aes(Age))+ geom_density(na.rm = TRUE)+ facet_grid(Pclass~Sex)

writeLines("Who is reporting NA under Age?\n")
table(Missing_Age = is.na(train$Age), Passenger_Class = train$Pclass, Sex = train$Sex) %>% 
    prop.table(margin = 2) %>% round(digits = 2)

writeLines("Who are the passengers reporing <blank> under Embarked?\n")
train[train$Embarked == "", ]

``` 

1.  The age distributions are approximately normal in all the six classes; however their means differ - decreasing with passenger class and men being older than women. Also, the `NA` under `Age` come from all the six classes above.
    To impute missing values for `Age`, we get the median values for the six classes above

2.  Two passengers are reporing `<blank>` under `Embarked`; both are travelling together but without any other siblings or parents on board.
    To identify where these two passengers embarked, We get the median fares paid by passengers in first class from the 3 embarkation ports to compare with the fare that these two passengers paid.

```{r eda-4}

age.medians = train %>% group_by(Pclass, Sex) %>% summarise(med = median(Age, na.rm = TRUE))

train %>% filter(Pclass == 1) %>% group_by(Embarked) %>% summarise(median(Fare))

```

1.  Comparing the fares they paid with median fares for other first class passengers, the 2 passengers with `<blank>` for `Embarked` most likely boarded from **C**. We therefore impute this value to `Embarked` in these two cases.
2.  We impute the median age of the class (function of `Pclass` and `Sex`) to `NA` under `Age`

```{r impute-data-1}

train[train$Embarked == "", "Embarked"] = "C"
train$Embarked = droplevels(train$Embarked)     #   Dropping the unused level
test$Embarked = droplevels(test$Embarked)       #   Repeating the step above for test subset

train[is.na(train$Age) & train$Pclass == 1 & train$Sex == "male", "Age"] = 
    age.medians[age.medians$Pclass == 1 & age.medians$Sex == "male", "med"]
train[is.na(train$Age) & train$Pclass == 2 & train$Sex == "male", "Age"] = 
    age.medians[age.medians$Pclass == 2 & age.medians$Sex == "male", "med"]
train[is.na(train$Age) & train$Pclass == 3 & train$Sex == "male", "Age"] = 
    age.medians[age.medians$Pclass == 3 & age.medians$Sex == "male", "med"]
train[is.na(train$Age) & train$Pclass == 1 & train$Sex == "female", "Age"] = 
    age.medians[age.medians$Pclass == 1 & age.medians$Sex == "female", "med"]
train[is.na(train$Age) & train$Pclass == 2 & train$Sex == "female", "Age"] = 
    age.medians[age.medians$Pclass == 2 & age.medians$Sex == "female", "med"]
train[is.na(train$Age) & train$Pclass == 3 & train$Sex == "female", "Age"] = 
    age.medians[age.medians$Pclass == 3 & age.medians$Sex == "female", "med"]

na.count(train)

```

We have now cleaned the train dataset.

1.  We make a reasonable assumption that the survival of a passenger is not dependent on his/her `Name`, `Ticket` and `Cabin`. For easier subsequent handling, we drop the non-essential features from the train subset. Finally, we save a baseline version of the updated train subset for future reference.
2.  We make the similar changes (of dropping the non-essential features) from the test subset and tabulate the missing data in the subset

```{r pre-proc-2}
feature.set = c("Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked")
train = train[, feature.set]
saveRDS(train, "../RDA/train.Rda")

test = test[, feature.set]

writeLines("\n")
writeLines("The table below enumerates the features from the test dataset that report NA values and the count of NA values under respective features\n")
na.count(test)

```

1.  In the test subset, the `Age` feature reports 86 `NA`. To these, we impute the median age of the relevant class (function of `Pclass` and `Sex`) from the **train** subset.
2.  We also identify the passenger record reporting `NA` inder `Fare`

```{r pre-proc-3}
test[is.na(test$Age) & test$Pclass == 1 & test$Sex == "male", "Age"] = 
    age.medians[age.medians$Pclass == 1 & age.medians$Sex == "male", "med"]
test[is.na(test$Age) & test$Pclass == 2 & test$Sex == "male", "Age"] = 
    age.medians[age.medians$Pclass == 2 & age.medians$Sex == "male", "med"]
test[is.na(test$Age) & test$Pclass == 3 & test$Sex == "male", "Age"] = 
    age.medians[age.medians$Pclass == 3 & age.medians$Sex == "male", "med"]
test[is.na(test$Age) & test$Pclass == 1 & test$Sex == "female", "Age"] = 
    age.medians[age.medians$Pclass == 1 & age.medians$Sex == "female", "med"]
test[is.na(test$Age) & test$Pclass == 2 & test$Sex == "female", "Age"] = 
    age.medians[age.medians$Pclass == 2 & age.medians$Sex == "female", "med"]
test[is.na(test$Age) & test$Pclass == 3 & test$Sex == "female", "Age"] = 
    age.medians[age.medians$Pclass == 3 & age.medians$Sex == "female", "med"]

test[is.na(test$Fare),]

```

1.  The passenger record reporting `NA` under `Fare` also reports `Pclass` = 3 and `Embarked` = S. To this `NA`, we impute the median value of the respective class (function of `Pclass` and `Embarked`) from the train subset.
2.  We confirm that the train subset is now clean and save a baseline for future reference.

```{r pre-proc-4}
test[is.na(test$Fare), "Fare"] = train %>% filter(Pclass == 3 & Embarked == "S") %>% 
                                        summarise(med = median(Fare))
na.count(test)

saveRDS(test, "../RDA/test.Rda")
```

Before proceeding further with feature engineering, it would be worthwhile to draw some Learning Curves to estimate if a basic logistical regression model suffers from high bias or high variance. This will inform our feature engineering better.

```{r learning-curve}

# We divide the training data into a training set and a validation set in the ratio of 70:30
set.seed(1970)
indx = sample(nrow(train), 0.7*nrow(train), replace = FALSE)
lc.steps = 25; lc.step.size = length(indx)/lc.steps
lc.set.size = seq(lc.step.size, length(indx), length.out = lc.steps) %>% round(digits = 0)

err.train = rep(0, lc.steps); err.val = err.train
for (i in 1:lc.steps) {
  glm.fit = glm(Survived~., data = train[indx[1:lc.set.size[i]],], 
                family = "binomial")
  prob = predict(glm.fit, newdata = train[indx[1:lc.set.size[i]],], type = "response")
  y = train$Survived[indx[1:lc.set.size[i]]]
  y = levels(y)[y] %>% as.numeric()
  err.train[i] = sum(-y*log(prob) - (1-y)*log(1-prob))/(length(y))

  prob = predict(glm.fit, newdata = train[-indx,], type = "response")
  y = train$Survived[-indx]
  y = levels(y)[y] %>% as.numeric()
  err.val[i] = sum(-y*log(prob) - (1-y)*log(1-prob))/(length(y))
}

err.df = cbind(Size = lc.set.size, Train = err.train, Val = err.val) %>% as.data.frame()

err.df %>% ggplot(aes(x = Size)) + geom_line(aes(y = Train, color = "Train.Set.Error"))+ 
    geom_line(aes(y = Val, color = "CrossVal.Set.Error"))+ 
    labs(title = "Learning Curves", x = "Training Set Sample Size", y = "Maximum Likelyhood Error Function")+
    scale_colour_manual(name="Key", values=c(Train.Set.Error ="red", CrossVal.Set.Error ="blue"))

```

The rapid and almost converged learning curves for train set and cross-validation set indicate that an un-penalised logistic regression model will suffers from high bias and if we are to improve the performance of out model then we will to build a model that uses additional features (feature interaction terms, feature power terms, etc).

To help evaluate the relative performance of differnt models built, we will establish a baseline performance measure for test set prediction accuracy using an un-penalised logistic regression model.

```{r est-test-error}
m = nrow(train)
est.test.err = 0
for (k in 1:5) {
    set.seed(k)
    indx = sample(1:m, 0.75*m)
    glm.fit = glm(Survived~., data = train[indx,], family = "binomial")
    prob = predict(glm.fit, newdata = train[indx,], type = "response")
    pred = prediction(prob, train$Survived[indx])
    perf = performance(pred, measure = "acc")
    max.acc.indx = perf@y.values %>% unlist() %>% as.vector() %>% which.max()
    bestcutoff = perf@x.values %>% unlist %>% as.vector() %>% .[max.acc.indx]
    
    prob = predict(glm.fit, newdata = train[-indx,], type = "response")
    pred = ifelse(prob < bestcutoff, 0, 1)
    test.err = mean(pred != train$Survived[-indx])
    est.test.err = test.err + est.test.err
}

print(paste("The estimated test error using an unpenalised logistic regression is", 
            round(est.test.err/5, digits = 4), sep = " "))

```

We will build different types of prediction models:

1.  Parametric Models
    a.  Un-penalised logistic regression with feature engineering
    b.  SVM with different kernels
    c.  Neural Networks
2.  Non-parametric models
    a.  K nearest Neighbours
    b.  Tree based








